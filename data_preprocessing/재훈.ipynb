{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": ""
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Professor names\n",
        "professor_names = ['김유섭', '김은주', '이정근', '양은샘', '신미영', '김선정']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "# Set a seed value\n",
        "SEED = 42\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get -q install -y fonts-noto-cjk\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "fm.fontManager.addfont('/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
        "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
        "sns.set(font='Noto Sans CJK JP', font_scale=.8)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('merged_reviews_by_professor.csv', encoding='utf-8-sig')\n",
        "df.head()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate embeddings"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
        "\n",
        "df['review_embedding'] = df['review'].apply(lambda x: model.encode(x))"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": ""
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": ""
      },
      "source": [
        "### Display basic information\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": ""
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": ""
      },
      "source": [
        "### Analyze review length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": ""
      },
      "source": [
        "df['review_length'] = df['review'].str.len()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['review'].str.len(), bins=50, kde=True)\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.xlabel('Review Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='professor', y='review_length', data=df)\n",
        "plt.title('Review Lengths by Professor')\n",
        "plt.xlabel('Professor')\n",
        "plt.ylabel('Review Length')"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": ""
      },
      "source": [
        "### Analyze word frequency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, professor in enumerate(professor_names):\n",
        "    professor_df = df[df['professor'] == professor]\n",
        "    all_reviews = ' '.join(professor_df['review'])\n",
        "\n",
        "    all_reviews.strip()\n",
        "\n",
        "    vectorizer = CountVectorizer(max_features=1000)\n",
        "    X = vectorizer.fit_transform([all_reviews])\n",
        "\n",
        "    frequency = np.sum(X.toarray(), axis=0)\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    word_frequencies = pd.DataFrame({'word': words, 'frequency': frequency})\n",
        "    word_frequencies = word_frequencies.sort_values(by='frequency', ascending=False)\n",
        "\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.barplot(x='frequency', y='word', data=word_frequencies.head(10))\n",
        "    plt.title(professor)\n",
        "    plt.xlabel('Frequency')\n",
        "    plt.ylabel('Word')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": ""
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, professor in enumerate(professor_names):\n",
        "    professor_df = df[df['professor'] == professor]\n",
        "    all_reviews = ' '.join(professor_df['review'])\n",
        "\n",
        "    all_reviews.strip()\n",
        "\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=500,\n",
        "        random_state=21,\n",
        "        max_font_size=110,\n",
        "        font_path='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',\n",
        "        background_color='white',\n",
        "        colormap='brg'\n",
        "    ).generate(all_reviews)\n",
        "\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(professor)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": ""
      },
      "source": [
        "### Visualize embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# UMAP dimensionality reduction\n",
        "umap_model = umap.UMAP(n_components=2, random_state=42, n_neighbors=5)\n",
        "embedding = umap_model.fit_transform(df['review_embedding'].tolist())\n",
        "\n",
        "# Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=50, contamination=0.02)\n",
        "outlier_labels = lof.fit_predict(embedding)\n",
        "\n",
        "umap_df = pd.DataFrame(embedding, columns=['umap_dim_1', 'umap_dim_2'])\n",
        "umap_df['outlier'] = outlier_labels\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(\n",
        "    x='umap_dim_1',\n",
        "    y='umap_dim_2',\n",
        "    hue='outlier',\n",
        "    style='outlier',\n",
        "    palette={1: 'blue', -1: 'red'},\n",
        "    markers={1: 'o', -1: 'X'},\n",
        "    data=umap_df,\n",
        "    s=40,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.title('UMAP Embedding with LOF Outlier Detection')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df[np.array(outlier_labels) == -1]['review']:\n",
        "    print(i)\n",
        "    print('---------')"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = np.array(df['review_embedding'].tolist())\n",
        "y = df['professor']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train SVM"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'SVM Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Random Forest"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Random Forest Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Optimization"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize -q"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Real\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': Integer(100, 200),\n",
        "    'max_depth': Integer(10, 20),\n",
        "    'min_samples_split': Integer(2, 10),\n",
        "    'min_samples_leaf': Integer(1, 5),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# n_iter: Number of optimization iterations\n",
        "# cv: Number of cross-validation folds\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=rf,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "print(f'Best parameters found: {bayes_search.best_params_}')\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = bayes_search.best_estimator_\n",
        "\n",
        "# Predict\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Bayes Optimized Random Forest Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Neural Network"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Define the network\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MyNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = ReviewDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = ReviewDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Instantiate\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = len(label_encoder.classes_)\n",
        "model = MyNN(input_size, num_classes)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train\n",
        "num_epochs = 50\n",
        "best_val_accuracy = 0.0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    val_loss = val_loss / len(test_loader)\n",
        "    val_accuracy = correct / total\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\n",
        "            f'Epoch {epoch}/{num_epochs}, '\n",
        "            f'Training Loss: {train_loss:.4f}, '\n",
        "            f'Validation Loss: {val_loss:.4f}, '\n",
        "            f'Validation Accuracy: {val_accuracy:.4f}'\n",
        "        )\n",
        "\n",
        "    # Save the best model yet\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), 'nn_model.pth')\n",
        "        print(f'New best: {best_val_accuracy:.4f}')"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accuracies, label='Validation Accuracy', color='green')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model state\n",
        "loaded_model = MyNN(input_size, num_classes)\n",
        "loaded_model.load_state_dict(torch.load('nn_model.pth'))\n",
        "loaded_model.eval()\n",
        "\n",
        "# Predict\n",
        "y_pred_tensor = loaded_model(X_test_tensor)\n",
        "_, y_pred = torch.max(y_pred_tensor, 1)\n",
        "y_pred = y_pred.numpy()\n",
        "\n",
        "# Evaluate\n",
        "accuracy_nn = accuracy_score(y_test, y_pred)\n",
        "print(f'NN Test Accuracy: {accuracy_nn:.4f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize result"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# t-SNE dimensionality reduction\n",
        "tsne_test = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X_test) - 1))\n",
        "tsne_test_results = tsne_test.fit_transform(X_test)\n",
        "\n",
        "tsne_test_df = pd.DataFrame(tsne_test_results, columns=['tsne_dim_1', 'tsne_dim_2'])\n",
        "tsne_test_df['true_labels'] = label_encoder.inverse_transform(y_test)\n",
        "tsne_test_df['predicted_labels'] = label_encoder.inverse_transform(y_pred)\n",
        "tsne_test_df['is_correct'] = y_test == y_pred\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(\n",
        "    x='tsne_dim_1',\n",
        "    y='tsne_dim_2',\n",
        "    hue='predicted_labels',\n",
        "    style='is_correct',\n",
        "    markers={True: 'o', False: 'X'},\n",
        "    data=tsne_test_df,\n",
        "    s=100,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.title('t-SNE of Test Set Embeddings')\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}