{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Professor names\n",
        "professor_names = ['김유섭', '김은주', '이정근', '양은샘', '신미영', '김선정']\n",
        "\n",
        "# Everytime session\n",
        "everytime_token = ''"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch lecture reviews from Everytime"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "import urllib.parse\n",
        "\n",
        "class Everytime:\n",
        "    def __init__(self, token):\n",
        "        self.token = token\n",
        "        self.session = None\n",
        "\n",
        "    async def __aenter__(self):\n",
        "        self.session = aiohttp.ClientSession()\n",
        "        return self\n",
        "\n",
        "    async def __aexit__(self, exc_type, exc, tb):\n",
        "        await self.session.close()\n",
        "\n",
        "    async def fetch_lectures(self, name):\n",
        "        url = 'https://api.everytime.kr/find/lecture/list/keyword'\n",
        "        headers = {\n",
        "            'User-Agent': 'Chrome/137.0.0.0',\n",
        "            'Accept': 'application/json, text/plain, */*',\n",
        "            'Content-Type': 'application/x-www-form-urlencoded',\n",
        "            'Cookie': f'etsid={self.token}'\n",
        "        }\n",
        "        data = urllib.parse.urlencode({\n",
        "            'campusId': '0',\n",
        "            'field': 'professor',\n",
        "            'keyword': name,\n",
        "            'limit': '10000',\n",
        "            'offset': '0'\n",
        "        })\n",
        "        async with self.session.post(url, headers=headers, data=data) as response:\n",
        "            if response.status == 200:\n",
        "                json_data = await response.json()\n",
        "                return json_data.get('result', {}).get('lectures', [])\n",
        "            else:\n",
        "                print(f'[Lecture] {name} failed with status {response.status}')\n",
        "                return []\n",
        "\n",
        "    async def fetch_articles(self, lecture):\n",
        "        url = 'https://api.everytime.kr/find/lecture/article/list'\n",
        "        headers = {\n",
        "            'User-Agent': 'Chrome/137.0.0.0',\n",
        "            'Accept': 'application/json, text/plain, */*',\n",
        "            'Content-Type': 'application/x-www-form-urlencoded',\n",
        "            'Cookie': f'etsid={self.token}'\n",
        "        }\n",
        "        data = urllib.parse.urlencode({\n",
        "            'lectureId': lecture['id'],\n",
        "            'limit': '10000',\n",
        "            'offset': '0',\n",
        "            'sort': 'id'\n",
        "        })\n",
        "        async with self.session.post(url, headers=headers, data=data) as response:\n",
        "            if response.status == 200:\n",
        "                json_data = await response.json()\n",
        "                lecture['articles'] = json_data.get('result', {}).get('articles', [])\n",
        "            else:\n",
        "                print(f'[Article] {lecture[\"id\"]} failed with status {response.status}')\n",
        "                lecture['articles'] = []\n",
        "        return lecture"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.asyncio import tqdm_asyncio\n",
        "\n",
        "async def get_everytime_reviews(professors):\n",
        "    async with Everytime(everytime_token) as et:\n",
        "        # Fetch lectures for each professor\n",
        "        lecture_tasks = [et.fetch_lectures(name) for name in professors]\n",
        "        lectures = await tqdm_asyncio.gather(*lecture_tasks)\n",
        "        lectures = [lec for sublist in lectures for lec in sublist]\n",
        "\n",
        "        # Fetch articles for each lecture\n",
        "        article_tasks = [et.fetch_articles(lecture) for lecture in lectures]\n",
        "        lectures_with_articles = await tqdm_asyncio.gather(*article_tasks)\n",
        "\n",
        "        return pd.DataFrame(lectures_with_articles)\n",
        "\n",
        "df = await get_everytime_reviews(professor_names)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.explode('articles').reset_index(drop=True)\n",
        "\n",
        "# JSON to table buckets\n",
        "articles = pd.json_normalize(df['articles'])\n",
        "\n",
        "# Drop the 'articles' column and concatenate the normalized review columns\n",
        "df = pd.concat([df.drop(columns=['articles']), articles], axis=1)\n",
        "\n",
        "# Rename and type conversion\n",
        "df = df[['professor', 'name', 'year', 'semester', 'text']]\n",
        "df = df.convert_dtypes(convert_integer=True)\n",
        "df.rename(columns={'text': 'review'}, inplace=True)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['professor'].value_counts()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['name'].value_counts()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 동명이인 및 전공 외 과목 처리"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['professor'].isin(professor_names)]\n",
        "df = df[~df['name'].isin([\n",
        "    '음성학과발음연습', '영어문법',\n",
        "    # '오디세이세미나1', '오디세이세미나2(리더십과 기업가정신)', '오디세이세미나3', '오디세이세미나4',\n",
        "    # '글로벌취업전략', '직무및기업탐색', '취업성공전략', '취업설계', '진로설계', '여대생커리어개발과취업전략', '해외취업및인턴준비과정'\n",
        "])]"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['professor'].value_counts()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['professor'] = pd.Categorical(\n",
        "    df['professor'],\n",
        "    categories=professor_names,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "# Sort and reset index\n",
        "df = df.sort_values('professor').reset_index(drop=True)"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save"
      ],
      "metadata": {
        "id": ""
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('everytime_reviews.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": ""
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}